{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "038d2610-3413-4c97-a72a-b18393e80b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "325ce2a3-ff81-4d37-b8a8-26378ff28896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bdac640-a3c8-4f72-b0f4-84584b98b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'test_yolo_image2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "351ad7b7-406b-48a2-acd8-f19e69ab4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "273c05cc-6ecf-480b-99a0-7698c2305918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 686, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c1d3188-92cd-449f-918c-e154d6fe0637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 3 cars, 1 truck, 1 traffic light, 1 dog, 54.1ms\n",
      "Speed: 2.5ms preprocess, 54.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71499539-84c2-4050-ae94-ed9981c65aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([ 0., 16.,  2.,  7.,  2.,  2.,  9.])\n",
       "conf: tensor([0.9095, 0.8066, 0.6594, 0.5610, 0.4786, 0.4577, 0.2782])\n",
       "data: tensor([[2.5818e+02, 5.5558e+01, 3.4413e+02, 2.9167e+02, 9.0952e-01, 0.0000e+00],\n",
       "        [3.2772e+02, 1.8651e+02, 4.0865e+02, 2.9754e+02, 8.0660e-01, 1.6000e+01],\n",
       "        [3.9352e+02, 1.5724e+02, 4.1863e+02, 1.7544e+02, 6.5940e-01, 2.0000e+00],\n",
       "        [4.4610e+02, 1.1702e+02, 5.7107e+02, 2.2267e+02, 5.6103e-01, 7.0000e+00],\n",
       "        [3.4259e+02, 1.4580e+02, 3.6997e+02, 1.7558e+02, 4.7857e-01, 2.0000e+00],\n",
       "        [4.4659e+02, 1.1690e+02, 5.7221e+02, 2.2269e+02, 4.5765e-01, 2.0000e+00],\n",
       "        [6.5412e+02, 4.9374e+01, 6.7747e+02, 8.4229e+01, 2.7815e-01, 9.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (386, 686)\n",
       "shape: torch.Size([7, 6])\n",
       "xywh: tensor([[301.1542, 173.6146,  85.9551, 236.1132],\n",
       "        [368.1860, 242.0257,  80.9231, 111.0248],\n",
       "        [406.0764, 166.3382,  25.1166,  18.2021],\n",
       "        [508.5811, 169.8477, 124.9705, 105.6496],\n",
       "        [356.2794, 160.6885,  27.3730,  29.7778],\n",
       "        [509.4021, 169.7931, 125.6199, 105.7923],\n",
       "        [665.7987,  66.8012,  23.3490,  34.8553]])\n",
       "xywhn: tensor([[0.4390, 0.4498, 0.1253, 0.6117],\n",
       "        [0.5367, 0.6270, 0.1180, 0.2876],\n",
       "        [0.5919, 0.4309, 0.0366, 0.0472],\n",
       "        [0.7414, 0.4400, 0.1822, 0.2737],\n",
       "        [0.5194, 0.4163, 0.0399, 0.0771],\n",
       "        [0.7426, 0.4399, 0.1831, 0.2741],\n",
       "        [0.9706, 0.1731, 0.0340, 0.0903]])\n",
       "xyxy: tensor([[258.1767,  55.5580, 344.1318, 291.6712],\n",
       "        [327.7245, 186.5133, 408.6476, 297.5381],\n",
       "        [393.5182, 157.2371, 418.6347, 175.4393],\n",
       "        [446.0958, 117.0229, 571.0663, 222.6725],\n",
       "        [342.5929, 145.7997, 369.9659, 175.5774],\n",
       "        [446.5922, 116.8969, 572.2120, 222.6892],\n",
       "        [654.1242,  49.3735, 677.4732,  84.2289]])\n",
       "xyxyn: tensor([[0.3764, 0.1439, 0.5016, 0.7556],\n",
       "        [0.4777, 0.4832, 0.5957, 0.7708],\n",
       "        [0.5736, 0.4074, 0.6103, 0.4545],\n",
       "        [0.6503, 0.3032, 0.8325, 0.5769],\n",
       "        [0.4994, 0.3777, 0.5393, 0.4549],\n",
       "        [0.6510, 0.3028, 0.8341, 0.5769],\n",
       "        [0.9535, 0.1279, 0.9876, 0.2182]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5caba60b-b333-4ab2-8932-f0caf40ed1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = results[0].plot()\n",
    "cv2.imshow('YOLO Algorithm in Image', detection)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "306c422a-b616-4d54-bba3-fe3d0ecefcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "class_names = model.names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "393e43e8-8231-4137-b98f-3c7b86667af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        confidence = box.conf[0]\n",
    "        class_label = int(box.cls[0])\n",
    "        class_name = class_names[class_label]\n",
    "        if confidence > 0.5:\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 3, 127), 2)\n",
    "            label = f\"{class_name}\"\n",
    "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('YOLO Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c145ed98-547c-479a-8ffd-9805aee5ae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.9095])\n",
      "data: tensor([[258.1767,  55.5580, 344.1318, 291.6712,   0.9095,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (386, 686)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[301.1542, 173.6146,  85.9551, 236.1132]])\n",
      "xywhn: tensor([[0.4390, 0.4498, 0.1253, 0.6117]])\n",
      "xyxy: tensor([[258.1767,  55.5580, 344.1318, 291.6712]])\n",
      "xyxyn: tensor([[0.3764, 0.1439, 0.5016, 0.7556]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([16.])\n",
      "conf: tensor([0.8066])\n",
      "data: tensor([[327.7245, 186.5133, 408.6476, 297.5381,   0.8066,  16.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (386, 686)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[368.1860, 242.0257,  80.9231, 111.0248]])\n",
      "xywhn: tensor([[0.5367, 0.6270, 0.1180, 0.2876]])\n",
      "xyxy: tensor([[327.7245, 186.5133, 408.6476, 297.5381]])\n",
      "xyxyn: tensor([[0.4777, 0.4832, 0.5957, 0.7708]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.6594])\n",
      "data: tensor([[393.5182, 157.2371, 418.6347, 175.4393,   0.6594,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (386, 686)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[406.0764, 166.3382,  25.1166,  18.2021]])\n",
      "xywhn: tensor([[0.5919, 0.4309, 0.0366, 0.0472]])\n",
      "xyxy: tensor([[393.5182, 157.2371, 418.6347, 175.4393]])\n",
      "xyxyn: tensor([[0.5736, 0.4074, 0.6103, 0.4545]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([7.])\n",
      "conf: tensor([0.5610])\n",
      "data: tensor([[4.4610e+02, 1.1702e+02, 5.7107e+02, 2.2267e+02, 5.6103e-01, 7.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (386, 686)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[508.5811, 169.8477, 124.9705, 105.6496]])\n",
      "xywhn: tensor([[0.7414, 0.4400, 0.1822, 0.2737]])\n",
      "xyxy: tensor([[446.0958, 117.0229, 571.0663, 222.6725]])\n",
      "xyxyn: tensor([[0.6503, 0.3032, 0.8325, 0.5769]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.4786])\n",
      "data: tensor([[342.5929, 145.7997, 369.9659, 175.5774,   0.4786,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (386, 686)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[356.2794, 160.6885,  27.3730,  29.7778]])\n",
      "xywhn: tensor([[0.5194, 0.4163, 0.0399, 0.0771]])\n",
      "xyxy: tensor([[342.5929, 145.7997, 369.9659, 175.5774]])\n",
      "xyxyn: tensor([[0.4994, 0.3777, 0.5393, 0.4549]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.4577])\n",
      "data: tensor([[4.4659e+02, 1.1690e+02, 5.7221e+02, 2.2269e+02, 4.5765e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (386, 686)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[509.4021, 169.7931, 125.6199, 105.7923]])\n",
      "xywhn: tensor([[0.7426, 0.4399, 0.1831, 0.2741]])\n",
      "xyxy: tensor([[446.5922, 116.8969, 572.2120, 222.6892]])\n",
      "xyxyn: tensor([[0.6510, 0.3028, 0.8341, 0.5769]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([9.])\n",
      "conf: tensor([0.2782])\n",
      "data: tensor([[6.5412e+02, 4.9374e+01, 6.7747e+02, 8.4229e+01, 2.7815e-01, 9.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (386, 686)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[665.7987,  66.8012,  23.3490,  34.8553]])\n",
      "xywhn: tensor([[0.9706, 0.1731, 0.0340, 0.0903]])\n",
      "xyxy: tensor([[654.1242,  49.3735, 677.4732,  84.2289]])\n",
      "xyxyn: tensor([[0.9535, 0.1279, 0.9876, 0.2182]])\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        print(box) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e1947-6798-42a8-9696-68d70292db1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
